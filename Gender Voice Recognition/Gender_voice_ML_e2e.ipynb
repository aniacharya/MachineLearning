{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Gender voice ML e2e.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqi2ijr5azs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#library\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Common Model Helpers\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# Importing Models\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Importing other tools\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n20O5PHNbDdy",
        "colab_type": "code",
        "outputId": "1f60855e-73b8-4a18-8f97-773bea771574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-3/master/Projects/gender_recognition_by_voice.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meanfreq</th>\n",
              "      <th>sd</th>\n",
              "      <th>median</th>\n",
              "      <th>Q25</th>\n",
              "      <th>Q75</th>\n",
              "      <th>IQR</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurt</th>\n",
              "      <th>sp.ent</th>\n",
              "      <th>sfm</th>\n",
              "      <th>mode</th>\n",
              "      <th>centroid</th>\n",
              "      <th>meanfun</th>\n",
              "      <th>minfun</th>\n",
              "      <th>maxfun</th>\n",
              "      <th>meandom</th>\n",
              "      <th>mindom</th>\n",
              "      <th>maxdom</th>\n",
              "      <th>dfrange</th>\n",
              "      <th>modindx</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.064241</td>\n",
              "      <td>0.032027</td>\n",
              "      <td>0.015071</td>\n",
              "      <td>0.090193</td>\n",
              "      <td>0.075122</td>\n",
              "      <td>12.863462</td>\n",
              "      <td>274.402906</td>\n",
              "      <td>0.893369</td>\n",
              "      <td>0.491918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.084279</td>\n",
              "      <td>0.015702</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.067310</td>\n",
              "      <td>0.040229</td>\n",
              "      <td>0.019414</td>\n",
              "      <td>0.092666</td>\n",
              "      <td>0.073252</td>\n",
              "      <td>22.423285</td>\n",
              "      <td>634.613855</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.513724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.107937</td>\n",
              "      <td>0.015826</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.009014</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.083829</td>\n",
              "      <td>0.036718</td>\n",
              "      <td>0.008701</td>\n",
              "      <td>0.131908</td>\n",
              "      <td>0.123207</td>\n",
              "      <td>30.757155</td>\n",
              "      <td>1024.927705</td>\n",
              "      <td>0.846389</td>\n",
              "      <td>0.478905</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.098706</td>\n",
              "      <td>0.015656</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.046512</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.072111</td>\n",
              "      <td>0.158011</td>\n",
              "      <td>0.096582</td>\n",
              "      <td>0.207955</td>\n",
              "      <td>0.111374</td>\n",
              "      <td>1.232831</td>\n",
              "      <td>4.177296</td>\n",
              "      <td>0.963322</td>\n",
              "      <td>0.727232</td>\n",
              "      <td>0.083878</td>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.088965</td>\n",
              "      <td>0.017798</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.201497</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.247119</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.079146</td>\n",
              "      <td>0.124656</td>\n",
              "      <td>0.078720</td>\n",
              "      <td>0.206045</td>\n",
              "      <td>0.127325</td>\n",
              "      <td>1.101174</td>\n",
              "      <td>4.333713</td>\n",
              "      <td>0.971955</td>\n",
              "      <td>0.783568</td>\n",
              "      <td>0.104261</td>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.106398</td>\n",
              "      <td>0.016931</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.712812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>5.484375</td>\n",
              "      <td>5.476562</td>\n",
              "      <td>0.208274</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   meanfreq        sd    median       Q25  ...    maxdom   dfrange   modindx  label\n",
              "0  0.059781  0.064241  0.032027  0.015071  ...  0.007812  0.000000  0.000000   male\n",
              "1  0.066009  0.067310  0.040229  0.019414  ...  0.054688  0.046875  0.052632   male\n",
              "2  0.077316  0.083829  0.036718  0.008701  ...  0.015625  0.007812  0.046512   male\n",
              "3  0.151228  0.072111  0.158011  0.096582  ...  0.562500  0.554688  0.247119   male\n",
              "4  0.135120  0.079146  0.124656  0.078720  ...  5.484375  5.476562  0.208274   male\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4aXubxPhiDg",
        "colab_type": "code",
        "outputId": "d66dc153-5c50-45ea-e77d-ed05589cb8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data['label'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['male', 'female'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0kjI642bDYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['sd','Q25','Q75','IQR','skew','kurt'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4kOr76ShSCj",
        "colab_type": "code",
        "outputId": "8d9750e0-7be5-46dc-bf79-25a52a9abaa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Converting LABEL to Number: Female - 0 and Male - 1\n",
        "data['label'] = data['label'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "data['label'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2epDEn_bDVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataDump  = data.copy()\n",
        "df = dataDump.drop(['label'], axis=1)\n",
        "df2 = df.drop([],axis = 1)\n",
        "df3 = pd.DataFrame()\n",
        "for col in df.columns:\n",
        "    df3[col] = df[col].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COZBf3hbcnAN",
        "colab_type": "code",
        "outputId": "dccfc0ba-d662-4698-a587-63da8d5cba3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "Target = ['label']\n",
        "data1_x_bin = df2\n",
        "data1_x_bin.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meanfreq</th>\n",
              "      <th>median</th>\n",
              "      <th>sp.ent</th>\n",
              "      <th>sfm</th>\n",
              "      <th>mode</th>\n",
              "      <th>centroid</th>\n",
              "      <th>meanfun</th>\n",
              "      <th>minfun</th>\n",
              "      <th>maxfun</th>\n",
              "      <th>meandom</th>\n",
              "      <th>mindom</th>\n",
              "      <th>maxdom</th>\n",
              "      <th>dfrange</th>\n",
              "      <th>modindx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.032027</td>\n",
              "      <td>0.893369</td>\n",
              "      <td>0.491918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.059781</td>\n",
              "      <td>0.084279</td>\n",
              "      <td>0.015702</td>\n",
              "      <td>0.275862</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.040229</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.513724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066009</td>\n",
              "      <td>0.107937</td>\n",
              "      <td>0.015826</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.009014</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>0.046875</td>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.036718</td>\n",
              "      <td>0.846389</td>\n",
              "      <td>0.478905</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077316</td>\n",
              "      <td>0.098706</td>\n",
              "      <td>0.015656</td>\n",
              "      <td>0.271186</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.046512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.158011</td>\n",
              "      <td>0.963322</td>\n",
              "      <td>0.727232</td>\n",
              "      <td>0.083878</td>\n",
              "      <td>0.151228</td>\n",
              "      <td>0.088965</td>\n",
              "      <td>0.017798</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.201497</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.247119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.124656</td>\n",
              "      <td>0.971955</td>\n",
              "      <td>0.783568</td>\n",
              "      <td>0.104261</td>\n",
              "      <td>0.135120</td>\n",
              "      <td>0.106398</td>\n",
              "      <td>0.016931</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.712812</td>\n",
              "      <td>0.007812</td>\n",
              "      <td>5.484375</td>\n",
              "      <td>5.476562</td>\n",
              "      <td>0.208274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   meanfreq    median    sp.ent  ...    maxdom   dfrange   modindx\n",
              "0  0.059781  0.032027  0.893369  ...  0.007812  0.000000  0.000000\n",
              "1  0.066009  0.040229  0.892193  ...  0.054688  0.046875  0.052632\n",
              "2  0.077316  0.036718  0.846389  ...  0.015625  0.007812  0.046512\n",
              "3  0.151228  0.158011  0.963322  ...  0.562500  0.554688  0.247119\n",
              "4  0.135120  0.124656  0.971955  ...  5.484375  5.476562  0.208274\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFQ_1J_pcm8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGinSDycbDOS",
        "colab_type": "code",
        "outputId": "c21fc000-0e3c-47aa-9d3a-a52d6cab74bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Target = ['Class']\n",
        "#data1_x_bin = pd.get_dummies(df2)\n",
        "\n",
        "# X = data1_x_bin\n",
        "# y = Target\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    svm.NuSVC(probability=True),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()    \n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = data[Target]  # Y \n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "Feature_Importance = {}\n",
        "\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, data1_x_bin, data[Target], cv  = cv_split,return_train_score=True,scoring='f1')\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(data1_x_bin, data[Target])\n",
        "\n",
        "    try:\n",
        "      Feature_Importance[MLA_name] = alg.feature_importances_\n",
        "    except AttributeError:\n",
        "      pass\n",
        "      \n",
        "    MLA_predict[MLA_name] = alg.predict(data1_x_bin)\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare\n",
        "MLA_compare['Difference'] = (MLA_compare['MLA Test Accuracy Mean']-MLA_compare['MLA Train Accuracy Mean'])*100\n",
        "MLA_compare\n",
        "\n",
        "#MLA_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLA Name</th>\n",
              "      <th>MLA Parameters</th>\n",
              "      <th>MLA Train Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy 3*STD</th>\n",
              "      <th>MLA Time</th>\n",
              "      <th>Difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979086</td>\n",
              "      <td>0.00833713</td>\n",
              "      <td>0.17359</td>\n",
              "      <td>-2.09138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97237</td>\n",
              "      <td>0.0153791</td>\n",
              "      <td>0.394807</td>\n",
              "      <td>-2.76299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
              "      <td>0.990199</td>\n",
              "      <td>0.972086</td>\n",
              "      <td>0.0123635</td>\n",
              "      <td>0.203159</td>\n",
              "      <td>-1.81132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
              "      <td>0.994436</td>\n",
              "      <td>0.970526</td>\n",
              "      <td>0.0130338</td>\n",
              "      <td>0.844483</td>\n",
              "      <td>-2.39109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
              "      <td>0.981072</td>\n",
              "      <td>0.968228</td>\n",
              "      <td>0.0189945</td>\n",
              "      <td>0.231526</td>\n",
              "      <td>-1.28437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
              "      <td>0.996943</td>\n",
              "      <td>0.965875</td>\n",
              "      <td>0.00853093</td>\n",
              "      <td>0.127068</td>\n",
              "      <td>-3.10675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
              "      <td>0.961298</td>\n",
              "      <td>0.962168</td>\n",
              "      <td>0.00900151</td>\n",
              "      <td>1.7158</td>\n",
              "      <td>0.0870267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
              "      <td>0.958297</td>\n",
              "      <td>0.958661</td>\n",
              "      <td>0.0109476</td>\n",
              "      <td>0.00932961</td>\n",
              "      <td>0.036325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
              "      <td>0.957498</td>\n",
              "      <td>0.958577</td>\n",
              "      <td>0.0142591</td>\n",
              "      <td>0.00754199</td>\n",
              "      <td>0.107831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
              "      <td>0.954163</td>\n",
              "      <td>0.954149</td>\n",
              "      <td>0.0177659</td>\n",
              "      <td>0.170805</td>\n",
              "      <td>-0.00137585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.950192</td>\n",
              "      <td>0.0200137</td>\n",
              "      <td>0.0236701</td>\n",
              "      <td>-4.98078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NuSVC</td>\n",
              "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
              "      <td>0.932446</td>\n",
              "      <td>0.9302</td>\n",
              "      <td>0.018099</td>\n",
              "      <td>1.22301</td>\n",
              "      <td>-0.224563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ExtraTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.922484</td>\n",
              "      <td>0.0590601</td>\n",
              "      <td>0.00312345</td>\n",
              "      <td>-7.75156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PassiveAggressiveClassifier</td>\n",
              "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
              "      <td>0.890048</td>\n",
              "      <td>0.892242</td>\n",
              "      <td>0.118087</td>\n",
              "      <td>0.0137266</td>\n",
              "      <td>0.219399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
              "      <td>0.852298</td>\n",
              "      <td>0.856845</td>\n",
              "      <td>0.040642</td>\n",
              "      <td>0.00274611</td>\n",
              "      <td>0.454735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GaussianProcessClassifier</td>\n",
              "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
              "      <td>0.788835</td>\n",
              "      <td>0.789598</td>\n",
              "      <td>0.0320146</td>\n",
              "      <td>3.35976</td>\n",
              "      <td>0.0762493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
              "      <td>0.861432</td>\n",
              "      <td>0.789017</td>\n",
              "      <td>0.0270395</td>\n",
              "      <td>0.00500345</td>\n",
              "      <td>-7.24154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
              "      <td>0.777467</td>\n",
              "      <td>0.776177</td>\n",
              "      <td>0.648745</td>\n",
              "      <td>0.0186504</td>\n",
              "      <td>-0.128951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "      <td>0.696473</td>\n",
              "      <td>0.704659</td>\n",
              "      <td>0.0753168</td>\n",
              "      <td>1.00177</td>\n",
              "      <td>0.818586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
              "      <td>0.693891</td>\n",
              "      <td>0.697379</td>\n",
              "      <td>0.643058</td>\n",
              "      <td>0.0105954</td>\n",
              "      <td>0.348831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
              "      <td>0.669049</td>\n",
              "      <td>0.660769</td>\n",
              "      <td>0.486105</td>\n",
              "      <td>0.00439641</td>\n",
              "      <td>-0.828073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
              "      <td>0.177399</td>\n",
              "      <td>0.185388</td>\n",
              "      <td>0.0521643</td>\n",
              "      <td>0.00390437</td>\n",
              "      <td>0.798875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         MLA Name  ...  Difference\n",
              "2            ExtraTreesClassifier  ...    -2.09138\n",
              "4          RandomForestClassifier  ...    -2.76299\n",
              "21                  XGBClassifier  ...    -1.81132\n",
              "3      GradientBoostingClassifier  ...    -2.39109\n",
              "0              AdaBoostClassifier  ...    -1.28437\n",
              "1               BaggingClassifier  ...    -3.10675\n",
              "6            LogisticRegressionCV  ...   0.0870267\n",
              "19     LinearDiscriminantAnalysis  ...    0.036325\n",
              "8               RidgeClassifierCV  ...    0.107831\n",
              "16                      LinearSVC  ... -0.00137585\n",
              "17         DecisionTreeClassifier  ...    -4.98078\n",
              "15                          NuSVC  ...   -0.224563\n",
              "18            ExtraTreeClassifier  ...    -7.75156\n",
              "7     PassiveAggressiveClassifier  ...    0.219399\n",
              "12                     GaussianNB  ...    0.454735\n",
              "5       GaussianProcessClassifier  ...   0.0762493\n",
              "13           KNeighborsClassifier  ...    -7.24154\n",
              "9                   SGDClassifier  ...   -0.128951\n",
              "14                            SVC  ...    0.818586\n",
              "10                     Perceptron  ...    0.348831\n",
              "20  QuadraticDiscriminantAnalysis  ...   -0.828073\n",
              "11                    BernoulliNB  ...    0.798875\n",
              "\n",
              "[22 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZM_Di9bcC8t",
        "colab_type": "code",
        "outputId": "b6d4abb3-2ae0-48ba-d6ce-41d377c2221c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MLA_compare.sort_values(by=\"MLA Test Accuracy 3*STD\",ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLA Name</th>\n",
              "      <th>MLA Parameters</th>\n",
              "      <th>MLA Train Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy 3*STD</th>\n",
              "      <th>MLA Time</th>\n",
              "      <th>Difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
              "      <td>0.777467</td>\n",
              "      <td>0.776177</td>\n",
              "      <td>0.648745</td>\n",
              "      <td>0.0186504</td>\n",
              "      <td>-0.128951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
              "      <td>0.693891</td>\n",
              "      <td>0.697379</td>\n",
              "      <td>0.643058</td>\n",
              "      <td>0.0105954</td>\n",
              "      <td>0.348831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
              "      <td>0.669049</td>\n",
              "      <td>0.660769</td>\n",
              "      <td>0.486105</td>\n",
              "      <td>0.00439641</td>\n",
              "      <td>-0.828073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PassiveAggressiveClassifier</td>\n",
              "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
              "      <td>0.890048</td>\n",
              "      <td>0.892242</td>\n",
              "      <td>0.118087</td>\n",
              "      <td>0.0137266</td>\n",
              "      <td>0.219399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "      <td>0.696473</td>\n",
              "      <td>0.704659</td>\n",
              "      <td>0.0753168</td>\n",
              "      <td>1.00177</td>\n",
              "      <td>0.818586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ExtraTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.922484</td>\n",
              "      <td>0.0590601</td>\n",
              "      <td>0.00312345</td>\n",
              "      <td>-7.75156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
              "      <td>0.177399</td>\n",
              "      <td>0.185388</td>\n",
              "      <td>0.0521643</td>\n",
              "      <td>0.00390437</td>\n",
              "      <td>0.798875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
              "      <td>0.852298</td>\n",
              "      <td>0.856845</td>\n",
              "      <td>0.040642</td>\n",
              "      <td>0.00274611</td>\n",
              "      <td>0.454735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GaussianProcessClassifier</td>\n",
              "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
              "      <td>0.788835</td>\n",
              "      <td>0.789598</td>\n",
              "      <td>0.0320146</td>\n",
              "      <td>3.35976</td>\n",
              "      <td>0.0762493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
              "      <td>0.861432</td>\n",
              "      <td>0.789017</td>\n",
              "      <td>0.0270395</td>\n",
              "      <td>0.00500345</td>\n",
              "      <td>-7.24154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.950192</td>\n",
              "      <td>0.0200137</td>\n",
              "      <td>0.0236701</td>\n",
              "      <td>-4.98078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
              "      <td>0.981072</td>\n",
              "      <td>0.968228</td>\n",
              "      <td>0.0189945</td>\n",
              "      <td>0.231526</td>\n",
              "      <td>-1.28437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NuSVC</td>\n",
              "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
              "      <td>0.932446</td>\n",
              "      <td>0.9302</td>\n",
              "      <td>0.018099</td>\n",
              "      <td>1.22301</td>\n",
              "      <td>-0.224563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
              "      <td>0.954163</td>\n",
              "      <td>0.954149</td>\n",
              "      <td>0.0177659</td>\n",
              "      <td>0.170805</td>\n",
              "      <td>-0.00137585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97237</td>\n",
              "      <td>0.0153791</td>\n",
              "      <td>0.394807</td>\n",
              "      <td>-2.76299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
              "      <td>0.957498</td>\n",
              "      <td>0.958577</td>\n",
              "      <td>0.0142591</td>\n",
              "      <td>0.00754199</td>\n",
              "      <td>0.107831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
              "      <td>0.994436</td>\n",
              "      <td>0.970526</td>\n",
              "      <td>0.0130338</td>\n",
              "      <td>0.844483</td>\n",
              "      <td>-2.39109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
              "      <td>0.990199</td>\n",
              "      <td>0.972086</td>\n",
              "      <td>0.0123635</td>\n",
              "      <td>0.203159</td>\n",
              "      <td>-1.81132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
              "      <td>0.958297</td>\n",
              "      <td>0.958661</td>\n",
              "      <td>0.0109476</td>\n",
              "      <td>0.00932961</td>\n",
              "      <td>0.036325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
              "      <td>0.961298</td>\n",
              "      <td>0.962168</td>\n",
              "      <td>0.00900151</td>\n",
              "      <td>1.7158</td>\n",
              "      <td>0.0870267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
              "      <td>0.996943</td>\n",
              "      <td>0.965875</td>\n",
              "      <td>0.00853093</td>\n",
              "      <td>0.127068</td>\n",
              "      <td>-3.10675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979086</td>\n",
              "      <td>0.00833713</td>\n",
              "      <td>0.17359</td>\n",
              "      <td>-2.09138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         MLA Name  ...  Difference\n",
              "9                   SGDClassifier  ...   -0.128951\n",
              "10                     Perceptron  ...    0.348831\n",
              "20  QuadraticDiscriminantAnalysis  ...   -0.828073\n",
              "7     PassiveAggressiveClassifier  ...    0.219399\n",
              "14                            SVC  ...    0.818586\n",
              "18            ExtraTreeClassifier  ...    -7.75156\n",
              "11                    BernoulliNB  ...    0.798875\n",
              "12                     GaussianNB  ...    0.454735\n",
              "5       GaussianProcessClassifier  ...   0.0762493\n",
              "13           KNeighborsClassifier  ...    -7.24154\n",
              "17         DecisionTreeClassifier  ...    -4.98078\n",
              "0              AdaBoostClassifier  ...    -1.28437\n",
              "15                          NuSVC  ...   -0.224563\n",
              "16                      LinearSVC  ... -0.00137585\n",
              "4          RandomForestClassifier  ...    -2.76299\n",
              "8               RidgeClassifierCV  ...    0.107831\n",
              "3      GradientBoostingClassifier  ...    -2.39109\n",
              "21                  XGBClassifier  ...    -1.81132\n",
              "19     LinearDiscriminantAnalysis  ...    0.036325\n",
              "6            LogisticRegressionCV  ...   0.0870267\n",
              "1               BaggingClassifier  ...    -3.10675\n",
              "2            ExtraTreesClassifier  ...    -2.09138\n",
              "\n",
              "[22 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58KlIFgrcCnK",
        "colab_type": "code",
        "outputId": "8b3d0f72-fd0a-4594-971b-78186dbfd295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "# sns.lineplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Test Accuracy Mean\", hue=\"MLA Name\", data=MLA_compare)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(18,8))\n",
        "cmap = sns.cubehelix_palette(dark=.1, light=0.8, as_cmap=True)\n",
        "# cmap = sns.palplot(sns.hls_palette(8, l=.3, s=.8))\n",
        "sns.scatterplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Name\", data=MLA_compare,hue=\"MLA Time\",palette=cmap ,sizes=(20, 200))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6e28186a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKoAAAHgCAYAAACFG4W+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiQNBBNVkiRJkiRJGgj/H9Ej1TrnJXtAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1296x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujhkpSLccCkf",
        "colab_type": "code",
        "outputId": "dfc1b42b-17c3-4892-eddc-aa7e799e3cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "# Get Importance Feature \n",
        "\n",
        "feature_names = data1_x_bin.columns\n",
        "feat_imp_df = pd.DataFrame.from_dict(Feature_Importance)\n",
        "feat_imp_df.index = feature_names\n",
        "feat_imp_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <th>XGBClassifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>meanfreq</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.048647</td>\n",
              "      <td>0.004060</td>\n",
              "      <td>0.043348</td>\n",
              "      <td>0.004697</td>\n",
              "      <td>0.014314</td>\n",
              "      <td>0.017220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.047337</td>\n",
              "      <td>0.002210</td>\n",
              "      <td>0.031386</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.026331</td>\n",
              "      <td>0.022175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sp.ent</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.108791</td>\n",
              "      <td>0.005098</td>\n",
              "      <td>0.100698</td>\n",
              "      <td>0.009241</td>\n",
              "      <td>0.043308</td>\n",
              "      <td>0.027404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sfm</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.064456</td>\n",
              "      <td>0.003946</td>\n",
              "      <td>0.062693</td>\n",
              "      <td>0.009851</td>\n",
              "      <td>0.062140</td>\n",
              "      <td>0.019855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mode</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.080361</td>\n",
              "      <td>0.020111</td>\n",
              "      <td>0.065361</td>\n",
              "      <td>0.013498</td>\n",
              "      <td>0.051697</td>\n",
              "      <td>0.033650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>centroid</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.049378</td>\n",
              "      <td>0.005029</td>\n",
              "      <td>0.040263</td>\n",
              "      <td>0.011870</td>\n",
              "      <td>0.071798</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meanfun</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.410554</td>\n",
              "      <td>0.922396</td>\n",
              "      <td>0.538535</td>\n",
              "      <td>0.863493</td>\n",
              "      <td>0.575570</td>\n",
              "      <td>0.660555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minfun</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.029876</td>\n",
              "      <td>0.021660</td>\n",
              "      <td>0.020355</td>\n",
              "      <td>0.030495</td>\n",
              "      <td>0.039410</td>\n",
              "      <td>0.056099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxfun</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.023448</td>\n",
              "      <td>0.000614</td>\n",
              "      <td>0.012164</td>\n",
              "      <td>0.005295</td>\n",
              "      <td>0.032222</td>\n",
              "      <td>0.017155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meandom</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.029807</td>\n",
              "      <td>0.003571</td>\n",
              "      <td>0.016987</td>\n",
              "      <td>0.013660</td>\n",
              "      <td>0.008269</td>\n",
              "      <td>0.022381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mindom</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.030021</td>\n",
              "      <td>0.003106</td>\n",
              "      <td>0.020146</td>\n",
              "      <td>0.003940</td>\n",
              "      <td>0.031460</td>\n",
              "      <td>0.032710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxdom</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.031243</td>\n",
              "      <td>0.003589</td>\n",
              "      <td>0.020235</td>\n",
              "      <td>0.006961</td>\n",
              "      <td>0.012715</td>\n",
              "      <td>0.033464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dfrange</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.015015</td>\n",
              "      <td>0.015617</td>\n",
              "      <td>0.014207</td>\n",
              "      <td>0.044822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modindx</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.020190</td>\n",
              "      <td>0.001587</td>\n",
              "      <td>0.012814</td>\n",
              "      <td>0.005138</td>\n",
              "      <td>0.016560</td>\n",
              "      <td>0.012510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          AdaBoostClassifier  ...  XGBClassifier\n",
              "meanfreq                0.02  ...       0.017220\n",
              "median                  0.04  ...       0.022175\n",
              "sp.ent                  0.06  ...       0.027404\n",
              "sfm                     0.12  ...       0.019855\n",
              "mode                    0.18  ...       0.033650\n",
              "centroid                0.02  ...       0.000000\n",
              "meanfun                 0.28  ...       0.660555\n",
              "minfun                  0.08  ...       0.056099\n",
              "maxfun                  0.02  ...       0.017155\n",
              "meandom                 0.06  ...       0.022381\n",
              "mindom                  0.02  ...       0.032710\n",
              "maxdom                  0.06  ...       0.033464\n",
              "dfrange                 0.00  ...       0.044822\n",
              "modindx                 0.04  ...       0.012510\n",
              "\n",
              "[14 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KpauBokcCdW",
        "colab_type": "code",
        "outputId": "b6384bca-e481-411c-a1cf-c7596134480b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "\n",
        "scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),\n",
        "                         columns=feat_imp_df.columns,\n",
        "                         index=feat_imp_df.index)\n",
        "\n",
        "scaled_fi['Overall'] = scaled_fi.sum(axis=1)\n",
        "print(scaled_fi.head())\n",
        "ordered_ranking = scaled_fi.sort_values('Overall', ascending=False)\n",
        "fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
        "sns.barplot(data=ordered_ranking, y=ordered_ranking.index, x='Overall', palette='magma')\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.grid(False)\n",
        "ax.set_title('Feature Importances for all Models');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          AdaBoostClassifier  ExtraTreesClassifier  ...  XGBClassifier   Overall\n",
            "meanfreq            0.071429              0.072899  ...       0.026069  0.244916\n",
            "median              0.142857              0.069542  ...       0.033570  0.318739\n",
            "sp.ent              0.214286              0.226971  ...       0.041486  0.723735\n",
            "sfm                 0.428571              0.113397  ...       0.030058  0.773473\n",
            "mode                0.642857              0.154142  ...       0.050942  1.057830\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHHCAYAAABdt4vcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 800x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raIwu90-rF6y",
        "colab_type": "code",
        "outputId": "533185cc-f7cd-49c2-ba1f-7a1b866e1c7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Re-Building the model with only top 10 Features \n",
        "\n",
        "scaled_sorted = scaled_fi.sort_values(by = ['Overall'], ascending = False)\n",
        "scaled_sorted[:5].index\n",
        "important_col = list(scaled_sorted[:10].index)\n",
        "Target = ['label']\n",
        "data1_x_bin = pd.get_dummies(df2)\n",
        "data1_x_bin = data1_x_bin[important_col]\n",
        "\n",
        "# X = data1_x_bin\n",
        "# y = Target\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    svm.NuSVC(probability=True),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()    \n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = data[Target]\n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "Feature_Importance = {}\n",
        "\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, data1_x_bin, data[Target], cv  = cv_split,return_train_score=True,scoring='f1')\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(data1_x_bin, data[Target])\n",
        "\n",
        "    try:\n",
        "      Feature_Importance[MLA_name] = alg.feature_importances_\n",
        "    except AttributeError:\n",
        "      pass\n",
        "      \n",
        "    MLA_predict[MLA_name] = alg.predict(data1_x_bin)\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare\n",
        "MLA_compare['Difference'] = (MLA_compare['MLA Test Accuracy Mean']-MLA_compare['MLA Train Accuracy Mean'])*100\n",
        "MLA_compare"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLA Name</th>\n",
              "      <th>MLA Parameters</th>\n",
              "      <th>MLA Train Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy Mean</th>\n",
              "      <th>MLA Test Accuracy 3*STD</th>\n",
              "      <th>MLA Time</th>\n",
              "      <th>Difference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.979528</td>\n",
              "      <td>0.0138079</td>\n",
              "      <td>0.167683</td>\n",
              "      <td>-2.04724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
              "      <td>0.989926</td>\n",
              "      <td>0.972823</td>\n",
              "      <td>0.0113675</td>\n",
              "      <td>0.17265</td>\n",
              "      <td>-1.71034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.971784</td>\n",
              "      <td>0.012687</td>\n",
              "      <td>0.408287</td>\n",
              "      <td>-2.82157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n",
              "      <td>0.994204</td>\n",
              "      <td>0.97058</td>\n",
              "      <td>0.0129028</td>\n",
              "      <td>0.694277</td>\n",
              "      <td>-2.36241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
              "      <td>0.981449</td>\n",
              "      <td>0.9693</td>\n",
              "      <td>0.0171604</td>\n",
              "      <td>0.201809</td>\n",
              "      <td>-1.21485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaggingClassifier</td>\n",
              "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
              "      <td>0.996988</td>\n",
              "      <td>0.964697</td>\n",
              "      <td>0.0146767</td>\n",
              "      <td>0.102648</td>\n",
              "      <td>-3.22906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegressionCV</td>\n",
              "      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n",
              "      <td>0.959866</td>\n",
              "      <td>0.961602</td>\n",
              "      <td>0.00999334</td>\n",
              "      <td>1.52279</td>\n",
              "      <td>0.17357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LinearDiscriminantAnalysis</td>\n",
              "      <td>{'n_components': None, 'priors': None, 'shrink...</td>\n",
              "      <td>0.958826</td>\n",
              "      <td>0.960206</td>\n",
              "      <td>0.0105898</td>\n",
              "      <td>0.0088469</td>\n",
              "      <td>0.137968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RidgeClassifierCV</td>\n",
              "      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n",
              "      <td>0.958254</td>\n",
              "      <td>0.959218</td>\n",
              "      <td>0.011265</td>\n",
              "      <td>0.00656228</td>\n",
              "      <td>0.0963709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n",
              "      <td>0.954808</td>\n",
              "      <td>0.954872</td>\n",
              "      <td>0.0173928</td>\n",
              "      <td>0.150235</td>\n",
              "      <td>0.00642351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.950108</td>\n",
              "      <td>0.0153445</td>\n",
              "      <td>0.0201975</td>\n",
              "      <td>-4.9892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ExtraTreeClassifier</td>\n",
              "      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.933241</td>\n",
              "      <td>0.0460891</td>\n",
              "      <td>0.00309508</td>\n",
              "      <td>-6.67586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NuSVC</td>\n",
              "      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n",
              "      <td>0.93463</td>\n",
              "      <td>0.932612</td>\n",
              "      <td>0.016527</td>\n",
              "      <td>1.02505</td>\n",
              "      <td>-0.201818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PassiveAggressiveClassifier</td>\n",
              "      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n",
              "      <td>0.909554</td>\n",
              "      <td>0.916524</td>\n",
              "      <td>0.0939994</td>\n",
              "      <td>0.0114909</td>\n",
              "      <td>0.696992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
              "      <td>0.868623</td>\n",
              "      <td>0.872066</td>\n",
              "      <td>0.0319892</td>\n",
              "      <td>0.00262203</td>\n",
              "      <td>0.344281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n",
              "      <td>0.816547</td>\n",
              "      <td>0.821012</td>\n",
              "      <td>0.251315</td>\n",
              "      <td>0.0160756</td>\n",
              "      <td>0.44658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
              "      <td>0.868141</td>\n",
              "      <td>0.804085</td>\n",
              "      <td>0.0323612</td>\n",
              "      <td>0.0044821</td>\n",
              "      <td>-6.40553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GaussianProcessClassifier</td>\n",
              "      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n",
              "      <td>0.791641</td>\n",
              "      <td>0.796941</td>\n",
              "      <td>0.0307972</td>\n",
              "      <td>3.34173</td>\n",
              "      <td>0.529928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "      <td>0.712744</td>\n",
              "      <td>0.720528</td>\n",
              "      <td>0.0405439</td>\n",
              "      <td>0.887525</td>\n",
              "      <td>0.778309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n",
              "      <td>0.708714</td>\n",
              "      <td>0.711883</td>\n",
              "      <td>0.586467</td>\n",
              "      <td>0.00895064</td>\n",
              "      <td>0.316862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n",
              "      <td>0.521211</td>\n",
              "      <td>0.542843</td>\n",
              "      <td>0.496105</td>\n",
              "      <td>0.00378489</td>\n",
              "      <td>2.16317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>BernoulliNB</td>\n",
              "      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n",
              "      <td>0.173639</td>\n",
              "      <td>0.180824</td>\n",
              "      <td>0.0539688</td>\n",
              "      <td>0.00383174</td>\n",
              "      <td>0.718516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         MLA Name  ...  Difference\n",
              "2            ExtraTreesClassifier  ...    -2.04724\n",
              "21                  XGBClassifier  ...    -1.71034\n",
              "4          RandomForestClassifier  ...    -2.82157\n",
              "3      GradientBoostingClassifier  ...    -2.36241\n",
              "0              AdaBoostClassifier  ...    -1.21485\n",
              "1               BaggingClassifier  ...    -3.22906\n",
              "6            LogisticRegressionCV  ...     0.17357\n",
              "19     LinearDiscriminantAnalysis  ...    0.137968\n",
              "8               RidgeClassifierCV  ...   0.0963709\n",
              "16                      LinearSVC  ...  0.00642351\n",
              "17         DecisionTreeClassifier  ...     -4.9892\n",
              "18            ExtraTreeClassifier  ...    -6.67586\n",
              "15                          NuSVC  ...   -0.201818\n",
              "7     PassiveAggressiveClassifier  ...    0.696992\n",
              "12                     GaussianNB  ...    0.344281\n",
              "9                   SGDClassifier  ...     0.44658\n",
              "13           KNeighborsClassifier  ...    -6.40553\n",
              "5       GaussianProcessClassifier  ...    0.529928\n",
              "14                            SVC  ...    0.778309\n",
              "10                     Perceptron  ...    0.316862\n",
              "20  QuadraticDiscriminantAnalysis  ...     2.16317\n",
              "11                    BernoulliNB  ...    0.718516\n",
              "\n",
              "[22 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5OQ2F4ltEpw",
        "colab_type": "text"
      },
      "source": [
        "Grid Search\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjLncqPGrFm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Class for Initilizing GridSearch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        if not set(models.keys()).issubset(set(params.keys())):\n",
        "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "        self.best_params = {}\n",
        "        self.feature_importance = {}\n",
        "        self.FeatureImportanceAlgo = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier']\n",
        "\n",
        "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=True):\n",
        "        for key in self.keys:\n",
        "            print(\"Running GridSearchCV for %s.\" % key)\n",
        "            model = self.models[key]\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs  \n",
        "            self.best_params[key]  = str(gs.best_params_)\n",
        "            if key in self.FeatureImportanceAlgo:\n",
        "              self.feature_importance[key]= gs.best_estimator_ .feature_importances_\n",
        "\n",
        "            # print (gs.best_params_.feature_importances_ )\n",
        "            # try:\n",
        "            #   print(gs.best_params_.feature_importances_ )\n",
        "            #   self.feature_importance[key]= gs.best_params_.feature_importances_ \n",
        "            # except AttributeError:\n",
        "            #   pass\n",
        "\n",
        "    def returnBestParamDF(self):\n",
        "      d = self.best_params\n",
        "      BestParamDF = pd.DataFrame.from_dict([d.keys(), d.values()]).T\n",
        "      return BestParamDF\n",
        "\n",
        "    # def Feature_Importance(self):\n",
        "    #   for each\n",
        "\n",
        "    # def returnFeatureImportance(self):\n",
        "\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEg29tbLrFjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "models1 = {\n",
        "    \n",
        "    'LogisticRegression':LogisticRegression(),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'KNNClassifier': KNeighborsClassifier(),\n",
        "    'SVC': SVC(),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
        "    \n",
        "}\n",
        "\n",
        "params1 = {\n",
        "    'LogisticRegression': { \"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"] },  # l1 lasso l2 ridge\n",
        "    'DecisionTreeClassifier': {'criterion' : ['gini', 'entropy'], 'splitter' : ['random', 'best'], 'max_depth':[2,5,10], 'min_samples_leaf':[2,5,10]},\n",
        "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
        "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
        "    'KNNClassifier':{ 'n_neighbors': [5,10,15,20], 'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
        "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
        "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
        "    'SVC': [\n",
        "        {'kernel': ['linear'], 'C': [1, 10]},\n",
        "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Ic1K63tWqL",
        "colab_type": "code",
        "outputId": "ef1f061c-f126-4f8b-dfc8-694d0db77054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "helper1 = EstimatorSelectionHelper(models1, params1)\n",
        "helper1.fit(data1_x_bin, data[Target], scoring='f1', n_jobs=-1)\n",
        "\n",
        "# To run with important column\n",
        "# ImpCol = ['','']\n",
        "# helper1.fit(data1_x_bin[ImpCol], data[Target], scoring='f1', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for LogisticRegression.\n",
            "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    2.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for DecisionTreeClassifier.\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    1.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for RandomForestClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for KNNClassifier.\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    5.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for SVC.\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    4.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for ExtraTreesClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for AdaBoostClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for GradientBoostingClassifier.\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocPzKfTztWlU",
        "colab_type": "code",
        "outputId": "5a415062-3bff-4b41-edd9-8cdef39064d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "feature_names = data1_x_bin.columns\n",
        "feat_imp_df = pd.DataFrame.from_dict(helper1.feature_importance)\n",
        "feat_imp_df.index = feature_names\n",
        "feat_imp_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>meanfun</th>\n",
              "      <td>0.944089</td>\n",
              "      <td>0.632559</td>\n",
              "      <td>0.497586</td>\n",
              "      <td>0.922417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mode</th>\n",
              "      <td>0.010026</td>\n",
              "      <td>0.047802</td>\n",
              "      <td>0.070319</td>\n",
              "      <td>0.015678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sfm</th>\n",
              "      <td>0.002161</td>\n",
              "      <td>0.064301</td>\n",
              "      <td>0.082678</td>\n",
              "      <td>0.004098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sp.ent</th>\n",
              "      <td>0.002934</td>\n",
              "      <td>0.098238</td>\n",
              "      <td>0.109844</td>\n",
              "      <td>0.009321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minfun</th>\n",
              "      <td>0.021409</td>\n",
              "      <td>0.028383</td>\n",
              "      <td>0.036585</td>\n",
              "      <td>0.020034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>centroid</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026771</td>\n",
              "      <td>0.044276</td>\n",
              "      <td>0.006380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxdom</th>\n",
              "      <td>0.015667</td>\n",
              "      <td>0.016463</td>\n",
              "      <td>0.030221</td>\n",
              "      <td>0.007163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031478</td>\n",
              "      <td>0.044244</td>\n",
              "      <td>0.004882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meandom</th>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.014439</td>\n",
              "      <td>0.032133</td>\n",
              "      <td>0.006576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meanfreq</th>\n",
              "      <td>0.002799</td>\n",
              "      <td>0.039566</td>\n",
              "      <td>0.052115</td>\n",
              "      <td>0.003450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          DecisionTreeClassifier  ...  GradientBoostingClassifier\n",
              "meanfun                 0.944089  ...                    0.922417\n",
              "mode                    0.010026  ...                    0.015678\n",
              "sfm                     0.002161  ...                    0.004098\n",
              "sp.ent                  0.002934  ...                    0.009321\n",
              "minfun                  0.021409  ...                    0.020034\n",
              "centroid                0.000000  ...                    0.006380\n",
              "maxdom                  0.015667  ...                    0.007163\n",
              "median                  0.000000  ...                    0.004882\n",
              "meandom                 0.000914  ...                    0.006576\n",
              "meanfreq                0.002799  ...                    0.003450\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t35fx_JktWU-",
        "colab_type": "code",
        "outputId": "17e5f7a3-dd7d-4796-a343-0008b84b8dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "\n",
        "scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),\n",
        "                         columns=feat_imp_df.columns,\n",
        "                         index=feat_imp_df.index)\n",
        "\n",
        "scaled_fi['Overall'] = scaled_fi.sum(axis=1)\n",
        "print(scaled_fi.head())\n",
        "ordered_ranking = scaled_fi.sort_values('Overall', ascending=False)\n",
        "fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
        "sns.barplot(data=ordered_ranking, y=ordered_ranking.index, x='Overall', palette='magma')\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.grid(False)\n",
        "ax.set_title('Feature Importances for all Models');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         DecisionTreeClassifier  ...   Overall\n",
            "meanfun                1.000000  ...  4.000000\n",
            "mode                   0.010620  ...  0.163695\n",
            "sfm                    0.002289  ...  0.195901\n",
            "sp.ent                 0.003108  ...  0.315433\n",
            "minfun                 0.022677  ...  0.076898\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHHCAYAAABdt4vcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 800x560 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAhz--HuBGk",
        "colab_type": "code",
        "outputId": "0de08ac2-3df9-41af-c418-ecc5a2be1a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "DecisionTreeClassifier\n",
            "RandomForestClassifier\n",
            "KNNClassifier\n",
            "SVC\n",
            "ExtraTreesClassifier\n",
            "AdaBoostClassifier\n",
            "GradientBoostingClassifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>C</th>\n",
              "      <th>algorithm</th>\n",
              "      <th>criterion</th>\n",
              "      <th>gamma</th>\n",
              "      <th>kernel</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>n_neighbors</th>\n",
              "      <th>penalty</th>\n",
              "      <th>splitter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.940284</td>\n",
              "      <td>0.955507</td>\n",
              "      <td>0.971264</td>\n",
              "      <td>0.0126532</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.944182</td>\n",
              "      <td>0.957755</td>\n",
              "      <td>0.970672</td>\n",
              "      <td>0.0108245</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.938931</td>\n",
              "      <td>0.951569</td>\n",
              "      <td>0.969754</td>\n",
              "      <td>0.0131809</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.948646</td>\n",
              "      <td>0.955939</td>\n",
              "      <td>0.968601</td>\n",
              "      <td>0.00898783</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.935238</td>\n",
              "      <td>0.949616</td>\n",
              "      <td>0.967742</td>\n",
              "      <td>0.0135316</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gini</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>82 rows  17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     estimator min_score  ... penalty splitter\n",
              "77          AdaBoostClassifier  0.940284  ...     NaN      NaN\n",
              "50      RandomForestClassifier  0.944182  ...     NaN      NaN\n",
              "75        ExtraTreesClassifier  0.938931  ...     NaN      NaN\n",
              "79  GradientBoostingClassifier  0.948646  ...     NaN      NaN\n",
              "21      DecisionTreeClassifier  0.935238  ...     NaN     best\n",
              "..                         ...       ...  ...     ...      ...\n",
              "4           LogisticRegression       NaN  ...      l1      NaN\n",
              "6           LogisticRegression       NaN  ...      l1      NaN\n",
              "8           LogisticRegression       NaN  ...      l1      NaN\n",
              "10          LogisticRegression       NaN  ...      l1      NaN\n",
              "12          LogisticRegression       NaN  ...      l1      NaN\n",
              "\n",
              "[82 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r46-XnJ6uBBR",
        "colab_type": "code",
        "outputId": "e93310e6-8a68-4fa9-c56d-ca0dedcbf7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "helper1.returnBestParamDF()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>{'C': 1000.0, 'penalty': 'l2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'n_estimators': 16}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNNClassifier</td>\n",
              "      <td>{'algorithm': 'auto', 'n_neighbors': 5}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'n_estimators': 16}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>{'learning_rate': 0.8, 'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            0                                                  1\n",
              "0          LogisticRegression                     {'C': 1000.0, 'penalty': 'l2'}\n",
              "1      DecisionTreeClassifier  {'criterion': 'gini', 'max_depth': 5, 'min_sam...\n",
              "2      RandomForestClassifier                               {'n_estimators': 16}\n",
              "3               KNNClassifier            {'algorithm': 'auto', 'n_neighbors': 5}\n",
              "4                         SVC                      {'C': 10, 'kernel': 'linear'}\n",
              "5        ExtraTreesClassifier                               {'n_estimators': 32}\n",
              "6          AdaBoostClassifier                               {'n_estimators': 16}\n",
              "7  GradientBoostingClassifier         {'learning_rate': 0.8, 'n_estimators': 32}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsEyUScxuk2M",
        "colab_type": "text"
      },
      "source": [
        "Voting Classifier - Soft & Hard Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zei5JHDvuA9a",
        "colab_type": "code",
        "outputId": "f99840b0-afc7-4d80-91f1-05d98aff5b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "vote_est = [\n",
        "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
        "    \n",
        "    ('rfc', ensemble.RandomForestClassifier()),\n",
        "    \n",
        "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
        "    ('knn', neighbors.KNeighborsClassifier()),\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "   ('xgb', XGBClassifier()),\n",
        "   ('lgbm',LGBMClassifier())\n",
        "\n",
        "]\n",
        "\n",
        "seed = 123\n",
        "skf = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = seed )\n",
        "#Hard Vote or majority rules\n",
        "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
        "vote_hard_cv = model_selection.cross_validate(vote_hard, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_hard.fit(data1_x_bin, data[Target])\n",
        "#print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
        "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
        "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
        "print('-'*10)\n",
        "\n",
        "#   Hard Voting \n",
        "# M1    1\n",
        "# M2     1\n",
        "# M3     0\n",
        "# M4    1\n",
        "\n",
        "# Fina = 1 \n",
        "\n",
        "# Soft Voting \n",
        "#     c1     c2\n",
        "# M1  0.2     0.8    \n",
        "# M2   0.4    0.6\n",
        "# M3  0.8      0.2 \n",
        "\n",
        "#  Soft   1.4     1.6   --> C2 (Higher) \n",
        "\n",
        "#Soft Vote or weighted probabilities\n",
        "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
        "vote_soft_cv = model_selection.cross_validate(vote_soft, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_soft.fit(data1_x_bin, data[Target])\n",
        "\n",
        "#print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
        "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
        "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
        "print('-'*10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Test w/bin score mean: 97.28\n",
            "Hard Voting Test w/bin score 3*std: +/- 1.72\n",
            "----------\n",
            "Soft Voting Test w/bin score mean: 97.33\n",
            "Soft Voting Test w/bin score 3*std: +/- 1.61\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHv_mNZfu9m6",
        "colab_type": "text"
      },
      "source": [
        "MLExtend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tatslmBdtWRV",
        "colab_type": "code",
        "outputId": "20245e15-c98d-41fc-aefc-815339b7c69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "\n",
        "lgbm_cl = LGBMClassifier(random_state=seed)\n",
        "rf_cl = RandomForestClassifier(10, random_state=seed)\n",
        "gdb_cl = GradientBoostingClassifier(random_state=seed)\n",
        "# logreg = LogisticRegression()\n",
        "\n",
        "\n",
        "sclf = StackingClassifier(classifiers=[lgbm_cl,gdb_cl],\n",
        "                          meta_classifier=rf_cl)\n",
        "\n",
        "\n",
        "scores = model_selection.cross_val_score(sclf, data1_x_bin, data[Target], \n",
        "                                              cv=3, scoring='f1')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" \n",
        "      % (scores.mean(), scores.std()))\n",
        "    \n",
        "\n",
        "# label = ['LGBM', 'Random Forest','GDB' 'Stacking Classifier']\n",
        "# clf_list = [lgbm_cl, rf_cl,gdb_cl, logreg]\n",
        "\n",
        "# for clf, label in zip([lgbm_cl, rf_cl,gdb_cl,sclf], \n",
        "#                       ['LGBM', \n",
        "#                        'Random Forest', \n",
        "#                        'GDB',\n",
        "#                        'StackingClassifier']):\n",
        "\n",
        "#     scores = model_selection.cross_val_score(clf, data1_x_bin, data[Target], \n",
        "#                                               cv=3, scoring='f1')\n",
        "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
        "#           % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.96 (+/- 0.01)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2aScyNirFd0",
        "colab_type": "code",
        "outputId": "619d3d05-63c9-4756-ed4e-71080b1efb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "dtree = GradientBoostingClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "dtree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cz0XnzBvDou",
        "colab_type": "code",
        "outputId": "a3f0a649-4462-41ef-d638-c779ecb9f771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, dtree.predict(X_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9705426356589147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdfPcG1wvDjk",
        "colab_type": "code",
        "outputId": "88a497ff-a394-41a4-dcdc-4e323881c59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import eli5\n",
        "\n",
        "from eli5.sklearn import PermutationImportance\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "dtree = RandomForestClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "dtree.predict(X_test)\n",
        "perm = PermutationImportance(dtree , random_state=101).fit(X_test, y_test)      # Evaluate the permutation importance \n",
        "eli5.show_weights(perm, feature_names = X_test.columns.values)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.4451\n",
              "                \n",
              "                    &plusmn; 0.0369\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                meanfun\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0120\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                mode\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0082\n",
              "                \n",
              "                    &plusmn; 0.0046\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                minfun\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0054\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                median\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.29%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0038\n",
              "                \n",
              "                    &plusmn; 0.0047\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                sfm\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0050\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                maxdom\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.56%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0019\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                meandom\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.61%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0072\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                sp.ent\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0006\n",
              "                \n",
              "                    &plusmn; 0.0043\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                meanfreq\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0006\n",
              "                \n",
              "                    &plusmn; 0.0032\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                centroid\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r4fvc95vDeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WhrAsAPwrPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FkFGezgwrLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8dd1zTGwrHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
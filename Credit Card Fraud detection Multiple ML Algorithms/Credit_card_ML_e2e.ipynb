{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit card ML e2e.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLEt2KQZCX4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#library\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Common Model Helpers\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# Importing Models\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Importing other tools\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWspODgBCfGz",
        "colab_type": "code",
        "outputId": "e76c685a-b505-4f13-c8bc-f4c5ceca9703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/insaid2018/Term-2/master/Data/credit_fraud.csv\")\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0     0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1     0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2     1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3     1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4     2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwupcfgACfBt",
        "colab_type": "code",
        "outputId": "392b60a9-50fc-48b8-c9d7-bb58426fe4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "data = data.drop(['Time'],axis=1)\n",
        "\n",
        "data['scaled_Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
        "data = data.drop(['Amount'],axis=1)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>scaled_Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.327088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>1.710945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>0.327791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>0.037727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3  ...       V28  Class  scaled_Amount\n",
              "0 -1.359807 -0.072781  2.536347  ... -0.021053      0       0.469380\n",
              "1  1.191857  0.266151  0.166480  ...  0.014724      0      -0.327088\n",
              "2 -1.358354 -1.340163  1.773209  ... -0.059752      0       1.710945\n",
              "3 -0.966272 -0.185226  1.792993  ...  0.061458      0       0.327791\n",
              "4 -1.158233  0.877737  1.548718  ...  0.215153      0       0.037727\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28btq4-4C1KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataDump  = data.copy()\n",
        "df = dataDump.drop(['Class'], axis=1)\n",
        "df2 = df.drop([],axis = 1)\n",
        "df3 = pd.DataFrame()\n",
        "for col in df.columns:\n",
        "    df3[col] = df[col].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY9yEKe2DWib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHYOGVlC1Ak",
        "colab_type": "code",
        "outputId": "f1ce0a3e-0f34-4a74-dc84-84329def5eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "Target = ['Class']\n",
        "data1_x_bin = df2\n",
        "data1_x_bin.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>scaled_Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0.469380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.327088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>1.710945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0.327791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0.037727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3  ...       V27       V28  scaled_Amount\n",
              "0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053       0.469380\n",
              "1  1.191857  0.266151  0.166480  ... -0.008983  0.014724      -0.327088\n",
              "2 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752       1.710945\n",
              "3 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458       0.327791\n",
              "4 -1.158233  0.877737  1.548718  ...  0.219422  0.215153       0.037727\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNQxd7mFmemF",
        "colab_type": "text"
      },
      "source": [
        "Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkyvZMcLC_X6",
        "colab_type": "code",
        "outputId": "336a5416-7e94-4cd2-b2c2-c168a728f027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#Target = ['Class']\n",
        "#data1_x_bin = pd.get_dummies(df2)\n",
        "\n",
        "# X = data1_x_bin\n",
        "# y = Target\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    #svm.NuSVC(probability=True),\n",
        "    svm.NuSVC(),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()    \n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = data[Target]  # Y \n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "Feature_Importance = {}\n",
        "\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, data1_x_bin, data[Target], cv  = cv_split,return_train_score=True,scoring='f1')\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(data1_x_bin, data[Target])\n",
        "\n",
        "    try:\n",
        "      Feature_Importance[MLA_name] = alg.feature_importances_\n",
        "    except AttributeError:\n",
        "      pass\n",
        "      \n",
        "    MLA_predict[MLA_name] = alg.predict(data1_x_bin)\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare\n",
        "MLA_compare['Difference'] = (MLA_compare['MLA Test Accuracy Mean']-MLA_compare['MLA Train Accuracy Mean'])*100\n",
        "MLA_compare\n",
        "\n",
        "#MLA_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b9318f4f24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m MLA = [\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#Ensemble Methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ensemble' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrFqZCX_Rszl",
        "colab_type": "text"
      },
      "source": [
        "Running the Model through Grid Search\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLygWnszRsTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Class for Initilizing GridSearch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        if not set(models.keys()).issubset(set(params.keys())):\n",
        "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "        self.best_params = {}\n",
        "        self.feature_importance = {}\n",
        "        self.FeatureImportanceAlgo = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier']\n",
        "\n",
        "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=True):\n",
        "        for key in self.keys:\n",
        "            print(\"Running GridSearchCV for %s.\" % key)\n",
        "            model = self.models[key]\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs  \n",
        "            self.best_params[key]  = str(gs.best_params_)\n",
        "            if key in self.FeatureImportanceAlgo:\n",
        "              self.feature_importance[key]= gs.best_estimator_ .feature_importances_\n",
        "\n",
        "            # print (gs.best_params_.feature_importances_ )\n",
        "            # try:\n",
        "            #   print(gs.best_params_.feature_importances_ )\n",
        "            #   self.feature_importance[key]= gs.best_params_.feature_importances_ \n",
        "            # except AttributeError:\n",
        "            #   pass\n",
        "\n",
        "    def returnBestParamDF(self):\n",
        "      d = self.best_params\n",
        "      BestParamDF = pd.DataFrame.from_dict([d.keys(), d.values()]).T\n",
        "      return BestParamDF\n",
        "\n",
        "    # def Feature_Importance(self):\n",
        "    #   for each\n",
        "\n",
        "    # def returnFeatureImportance(self):\n",
        "\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev5o9eQICe8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "models1 = {\n",
        "    \n",
        "    'LogisticRegression':LogisticRegression(),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'KNNClassifier': KNeighborsClassifier(),\n",
        "    'SVC': SVC(),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
        "    \n",
        "}\n",
        "\n",
        "params1 = {\n",
        "    'LogisticRegression': { \"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"] },  # l1 lasso l2 ridge\n",
        "    'DecisionTreeClassifier': {'criterion' : ['gini', 'entropy'], 'splitter' : ['random', 'best'], 'max_depth':[2,5,10], 'min_samples_leaf':[2,5,10]},\n",
        "    'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
        "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] },\n",
        "    'KNNClassifier':{ 'n_neighbors': [5,10,15,20], 'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
        "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] },\n",
        "    'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
        "    'SVC': [\n",
        "        {'kernel': ['linear'], 'C': [1, 10]},\n",
        "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-yPEAYCCeyn",
        "colab_type": "code",
        "outputId": "b688d800-ec8d-40ee-d251-03296fb6b875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "helper1 = EstimatorSelectionHelper(models1, params1)\n",
        "helper1.fit(data1_x_bin, data[Target], scoring='f1', n_jobs=-1)\n",
        "\n",
        "# To run with important column\n",
        "# ImpCol = ['','']\n",
        "# helper1.fit(data1_x_bin[ImpCol], data[Target], scoring='f1', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for LogisticRegression.\n",
            "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    2.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for DecisionTreeClassifier.\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    3.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for RandomForestClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for KNNClassifier.\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.7min finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for SVC.\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for ExtraTreesClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for AdaBoostClassifier.\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    2.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for GradientBoostingClassifier.\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3l91l7uCeiN",
        "colab_type": "code",
        "outputId": "399aea56-5d4f-416d-815d-ffe21315c452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "feature_names = data1_x_bin.columns\n",
        "feat_imp_df = pd.DataFrame.from_dict(helper1.feature_importance)\n",
        "feat_imp_df.index = feature_names\n",
        "feat_imp_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004583</td>\n",
              "      <td>0.005394</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005831</td>\n",
              "      <td>0.012079</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079370</td>\n",
              "      <td>0.094180</td>\n",
              "      <td>0.005766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023345</td>\n",
              "      <td>0.065498</td>\n",
              "      <td>0.223273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002588</td>\n",
              "      <td>0.010986</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014140</td>\n",
              "      <td>0.014418</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002914</td>\n",
              "      <td>0.012097</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.006925</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008630</td>\n",
              "      <td>0.036163</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109559</td>\n",
              "      <td>0.056923</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.121378</td>\n",
              "      <td>0.139381</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>0.949384</td>\n",
              "      <td>0.175901</td>\n",
              "      <td>0.164442</td>\n",
              "      <td>0.673945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007009</td>\n",
              "      <td>0.010029</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>0.050616</td>\n",
              "      <td>0.177946</td>\n",
              "      <td>0.116582</td>\n",
              "      <td>0.001918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003592</td>\n",
              "      <td>0.005928</td>\n",
              "      <td>0.007688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063468</td>\n",
              "      <td>0.025456</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.114068</td>\n",
              "      <td>0.127369</td>\n",
              "      <td>0.087410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>0.021567</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.008517</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008558</td>\n",
              "      <td>0.005130</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>0.007265</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008050</td>\n",
              "      <td>0.003972</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003587</td>\n",
              "      <td>0.005159</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003302</td>\n",
              "      <td>0.010550</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009626</td>\n",
              "      <td>0.003828</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003804</td>\n",
              "      <td>0.011755</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009027</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005077</td>\n",
              "      <td>0.005306</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scaled_Amount</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003842</td>\n",
              "      <td>0.006536</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               DecisionTreeClassifier  ...  GradientBoostingClassifier\n",
              "V1                           0.000000  ...                    0.000000\n",
              "V2                           0.000000  ...                    0.000000\n",
              "V3                           0.000000  ...                    0.005766\n",
              "V4                           0.000000  ...                    0.223273\n",
              "V5                           0.000000  ...                    0.000000\n",
              "V6                           0.000000  ...                    0.000000\n",
              "V7                           0.000000  ...                    0.000000\n",
              "V8                           0.000000  ...                    0.000000\n",
              "V9                           0.000000  ...                    0.000000\n",
              "V10                          0.000000  ...                    0.000000\n",
              "V11                          0.000000  ...                    0.000000\n",
              "V12                          0.949384  ...                    0.673945\n",
              "V13                          0.000000  ...                    0.000000\n",
              "V14                          0.050616  ...                    0.001918\n",
              "V15                          0.000000  ...                    0.007688\n",
              "V16                          0.000000  ...                    0.000000\n",
              "V17                          0.000000  ...                    0.087410\n",
              "V18                          0.000000  ...                    0.000000\n",
              "V19                          0.000000  ...                    0.000000\n",
              "V20                          0.000000  ...                    0.000000\n",
              "V21                          0.000000  ...                    0.000000\n",
              "V22                          0.000000  ...                    0.000000\n",
              "V23                          0.000000  ...                    0.000000\n",
              "V24                          0.000000  ...                    0.000000\n",
              "V25                          0.000000  ...                    0.000000\n",
              "V26                          0.000000  ...                    0.000000\n",
              "V27                          0.000000  ...                    0.000000\n",
              "V28                          0.000000  ...                    0.000000\n",
              "scaled_Amount                0.000000  ...                    0.000000\n",
              "\n",
              "[29 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7mJ5bxtSqoW",
        "colab_type": "code",
        "outputId": "f97d4627-6398-48ae-b6d0-16621d59d2d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "DecisionTreeClassifier\n",
            "RandomForestClassifier\n",
            "KNNClassifier\n",
            "SVC\n",
            "ExtraTreesClassifier\n",
            "AdaBoostClassifier\n",
            "GradientBoostingClassifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>C</th>\n",
              "      <th>algorithm</th>\n",
              "      <th>criterion</th>\n",
              "      <th>gamma</th>\n",
              "      <th>kernel</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>min_samples_leaf</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>n_neighbors</th>\n",
              "      <th>penalty</th>\n",
              "      <th>splitter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.889855</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0829006</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.874608</td>\n",
              "      <td>1</td>\n",
              "      <td>0.112416</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.922039</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0562169</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.410961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.922039</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0562169</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>82 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 estimator min_score mean_score  ... n_neighbors penalty splitter\n",
              "44  DecisionTreeClassifier       0.8   0.889855  ...         NaN     NaN   random\n",
              "50  RandomForestClassifier  0.727273   0.874608  ...         NaN     NaN      NaN\n",
              "35  DecisionTreeClassifier  0.869565   0.922039  ...         NaN     NaN     best\n",
              "36  DecisionTreeClassifier         0   0.466667  ...         NaN     NaN   random\n",
              "37  DecisionTreeClassifier  0.869565   0.922039  ...         NaN     NaN     best\n",
              "..                     ...       ...        ...  ...         ...     ...      ...\n",
              "4       LogisticRegression       NaN        NaN  ...         NaN      l1      NaN\n",
              "6       LogisticRegression       NaN        NaN  ...         NaN      l1      NaN\n",
              "8       LogisticRegression       NaN        NaN  ...         NaN      l1      NaN\n",
              "10      LogisticRegression       NaN        NaN  ...         NaN      l1      NaN\n",
              "12      LogisticRegression       NaN        NaN  ...         NaN      l1      NaN\n",
              "\n",
              "[82 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vFVcUOOSqk3",
        "colab_type": "code",
        "outputId": "d159960b-6bd1-42fd-f435-1f5c74e5653d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "helper1.returnBestParamDF()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>{'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNNClassifier</td>\n",
              "      <td>{'algorithm': 'auto', 'n_neighbors': 5}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVC</td>\n",
              "      <td>{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>{'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>{'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>{'learning_rate': 1.0, 'n_estimators': 32}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            0                                                  1\n",
              "0          LogisticRegression                        {'C': 0.1, 'penalty': 'l2'}\n",
              "1      DecisionTreeClassifier  {'criterion': 'entropy', 'max_depth': 2, 'min_...\n",
              "2      RandomForestClassifier                               {'n_estimators': 32}\n",
              "3               KNNClassifier            {'algorithm': 'auto', 'n_neighbors': 5}\n",
              "4                         SVC          {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
              "5        ExtraTreesClassifier                               {'n_estimators': 32}\n",
              "6          AdaBoostClassifier                               {'n_estimators': 32}\n",
              "7  GradientBoostingClassifier         {'learning_rate': 1.0, 'n_estimators': 32}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yHN0U5MSqWn",
        "colab_type": "code",
        "outputId": "35cea14f-01e8-4961-b72b-a0ba82365c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "vote_est = [\n",
        "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
        "    \n",
        "    ('rfc', ensemble.RandomForestClassifier()),\n",
        "    \n",
        "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
        "    ('knn', neighbors.KNeighborsClassifier()),\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "   ('xgb', XGBClassifier()),\n",
        "   ('lgbm',LGBMClassifier())\n",
        "\n",
        "]\n",
        "\n",
        "seed = 123\n",
        "skf = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = seed )\n",
        "#Hard Vote or majority rules\n",
        "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
        "vote_hard_cv = model_selection.cross_validate(vote_hard, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_hard.fit(data1_x_bin, data[Target])\n",
        "#print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
        "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
        "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
        "print('-'*10)\n",
        "\n",
        "#Soft Vote or weighted probabilities\n",
        "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
        "vote_soft_cv = model_selection.cross_validate(vote_soft, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_soft.fit(data1_x_bin, data[Target])\n",
        "\n",
        "#print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
        "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
        "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
        "print('-'*10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hard Voting Test w/bin score mean: 88.09\n",
            "Hard Voting Test w/bin score 3*std: +/- 23.21\n",
            "----------\n",
            "Soft Voting Test w/bin score mean: 89.17\n",
            "Soft Voting Test w/bin score 3*std: +/- 22.69\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksTk7-pH7mwr",
        "colab_type": "text"
      },
      "source": [
        "MLExtend\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9leV8AYTAgk",
        "colab_type": "code",
        "outputId": "6fada6a2-8ee3-43ff-dd90-a4aa46a9f16b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "\n",
        "lgbm_cl = LGBMClassifier(random_state=seed)\n",
        "rf_cl = RandomForestClassifier(10, random_state=seed)\n",
        "gdb_cl = GradientBoostingClassifier(random_state=seed)\n",
        "# logreg = LogisticRegression()\n",
        "\n",
        "\n",
        "sclf = StackingClassifier(classifiers=[lgbm_cl,gdb_cl],\n",
        "                          meta_classifier=rf_cl)\n",
        "\n",
        "\n",
        "scores = model_selection.cross_val_score(sclf, data1_x_bin, data[Target], \n",
        "                                              cv=3, scoring='f1')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" \n",
        "      % (scores.mean(), scores.std()))\n",
        "    \n",
        "\n",
        "# label = ['LGBM', 'Random Forest','GDB' 'Stacking Classifier']\n",
        "# clf_list = [lgbm_cl, rf_cl,gdb_cl, logreg]\n",
        "\n",
        "# for clf, label in zip([lgbm_cl, rf_cl,gdb_cl,sclf], \n",
        "#                       ['LGBM', \n",
        "#                        'Random Forest', \n",
        "#                        'GDB',\n",
        "#                        'StackingClassifier']):\n",
        "\n",
        "#     scores = model_selection.cross_val_score(clf, data1_x_bin, data[Target], \n",
        "#                                               cv=3, scoring='f1')\n",
        "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
        "#           % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.92 (+/- 0.04)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1qO-ptD7_wG",
        "colab_type": "code",
        "outputId": "fa54fdf9-5b50-4de5-a503-927a10900ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "from vecstack import stacking\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "#1st level model\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "models = [lgbm_cl,rf_cl,gdb_cl]\n",
        "S_train, S_test = stacking(models, X_train, y_train, X_test, \n",
        "    regression = False, metric = metrics.f1_score, n_folds = 4 , \n",
        "    shuffle = True, random_state = 0, verbose = 2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [f1_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [LGBMClassifier]\n",
            "    fold  0:  [0.87500000]\n",
            "    fold  1:  [0.83333333]\n",
            "    fold  2:  [0.27272727]\n",
            "    fold  3:  [0.80000000]\n",
            "    ----\n",
            "    MEAN:     [0.69526515] + [0.24539513]\n",
            "    FULL:     [0.66666667]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.85714286]\n",
            "    fold  1:  [1.00000000]\n",
            "    fold  2:  [0.88888889]\n",
            "    fold  3:  [0.85714286]\n",
            "    ----\n",
            "    MEAN:     [0.90079365] + [0.05872480]\n",
            "    FULL:     [0.92000000]\n",
            "\n",
            "model  2:     [GradientBoostingClassifier]\n",
            "    fold  0:  [0.85714286]\n",
            "    fold  1:  [0.83333333]\n",
            "    fold  2:  [0.80000000]\n",
            "    fold  3:  [0.80000000]\n",
            "    ----\n",
            "    MEAN:     [0.82261905] + [0.02413468]\n",
            "    FULL:     [0.82758621]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj6uIKg07_s0",
        "colab_type": "code",
        "outputId": "460e9bb9-8f57-4445-e118-70c1e9e598db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#2nd level model\n",
        "# Initialize 2nd level model\n",
        "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=100, max_depth=3)\n",
        "    \n",
        "# Fit 2nd level model\n",
        "model = model.fit(S_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(S_test)\n",
        "\n",
        "# Final prediction score\n",
        "print('Final prediction score: [%.8f]' % metrics.f1_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final prediction score: [1.00000000]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYvcPwVT7_pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7eykGdTAPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwi0kyq_TALy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}